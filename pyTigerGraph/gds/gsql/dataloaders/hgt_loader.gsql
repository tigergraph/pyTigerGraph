CREATE QUERY hgt_loader_{QUERYSUFFIX}(
    SET<VERTEX> input_vertices,
    INT num_hops=2, 
    BOOL shuffle=FALSE,
    STRING filter_by,
    SET<STRING> v_types,
    SET<STRING> e_types,
    SET<STRING> seed_types,
    STRING delimiter,
    INT num_chunks=2,
    STRING kafka_address="",
    STRING kafka_topic="",
    INT kafka_topic_partitions=1,
    STRING kafka_max_size="104857600",
    INT kafka_timeout=300000,
    STRING security_protocol="",
    STRING sasl_mechanism="",
    STRING sasl_username="",
    STRING sasl_password="",
    STRING ssl_ca_location="",
    STRING ssl_certificate_location="",
    STRING ssl_key_location="",
    STRING ssl_key_password="",
    STRING ssl_endpoint_identification_algorithm="",
    STRING sasl_kerberos_service_name="",
    STRING sasl_kerberos_keytab="",
    STRING sasl_kerberos_principal=""
) SYNTAX V1 { 
    /*
    This query generates the neighborhood subgraphs of given seed vertices (i.e., `input_vertices`).
    If seed vertices are not given, then it will divide all vertices into `num_batches`, and use each 
    batch as seeds.

    Parameters :
      input_vertices : Seed vertices to gather neighborhood subgraphs.
      num_batches    : Number of batches to divide all vertices into.
      num_hops       : Number of hops to traverse to get neighbors.
      shuffle        : Whether to shuffle vertices before collecting data.
      filter_by      : A Boolean attribute to determine which vertices are eligible as seeds.
                       Only effective when `input_vertices` is NULL.
      v_types        : Vertex types to be included.
      e_types        : Edge types to be included.
      seed_types     : Vertex types to be included as seeds.
      kafka_address  : Address of the Kafka cluster to send data to.
      kafka_topic    : The Kafka topic to send data to.
      security_protocol : Security prototol for Kafka.
      sasl_mechanism : Authentication mechanism for Kafka.
      sasl_username  : SASL username for Kafka. 
      sasl_password  : SASL password for Kafka. 
      ssl_ca_location: Path to CA certificate for verifying the Kafka broker key.
    */
    SumAccum<INT> @tmp_id;

    # If getting all vertices of given types
    IF input_vertices.size()==0 THEN
        start = {seed_types};
        # Filter seeds if needed
        seeds = SELECT s
            FROM start:s
            WHERE filter_by is NULL OR s.getAttr(filter_by, "BOOL");
        # Shuffle vertex ID if needed
        IF shuffle THEN
            INT num_vertices = seeds.size();
            res = SELECT s 
                FROM seeds:s
                POST-ACCUM s.@tmp_id = floor(rand()*num_vertices)
                LIMIT 1;
        ELSE
            res = SELECT s 
                FROM seeds:s
                POST-ACCUM s.@tmp_id = getvid(s)
                LIMIT 1;
        END;

        # Export data
        # If using kafka to export 
        IF kafka_address != "" THEN
            SumAccum<STRING> @@kafka_error;

            # Initialize Kafka producer
            UINT producer = init_kafka_producer(
                kafka_address, kafka_max_size, security_protocol, 
                sasl_mechanism, sasl_username, sasl_password, ssl_ca_location,
                ssl_certificate_location, ssl_key_location, ssl_key_password,
                ssl_endpoint_identification_algorithm, sasl_kerberos_service_name,
                sasl_kerberos_keytab, sasl_kerberos_principal);

            FOREACH chunk IN RANGE[0, num_chunks-1] DO
                res = SELECT s 
                    FROM seeds:s
                    WHERE s.@tmp_id % num_chunks == chunk
                    POST-ACCUM
                        LIST<STRING> msg = hgt_loader_sub_{QUERYSUFFIX}(s, delimiter, num_hops, e_types, v_types),
                        BOOL is_first=True,
                        FOREACH i in msg DO
                            IF is_first THEN
                                INT kafka_errcode = write_to_kafka(producer, kafka_topic, getvid(s)%kafka_topic_partitions, "vertex_batch_" + stringify(getvid(s)), i),
                                IF kafka_errcode!=0 THEN 
                                    @@kafka_error += ("Error sending vertex batch for " + stringify(getvid(s)) + ": "+ stringify(kafka_errcode) + "\\n")
                                END,
                                is_first = False
                            ELSE 
                                INT kafka_errcode = write_to_kafka(producer, kafka_topic, getvid(s)%kafka_topic_partitions, "edge_batch_" + stringify(getvid(s)), i),
                                IF kafka_errcode!=0 THEN 
                                    @@kafka_error += ("Error sending edge batch for " + stringify(getvid(s)) + ": "+ stringify(kafka_errcode) + "\\n")
                                END
                            END
                        END
                    LIMIT 1;
            END;

            FOREACH i IN RANGE[0, kafka_topic_partitions-1] DO
                INT kafka_errcode = write_to_kafka(producer, kafka_topic, i, "STOP", "");
                IF kafka_errcode!=0 THEN 
                    @@kafka_error += ("Error sending STOP signal to topic partition " + stringify(i) + ": " + stringify(kafka_errcode) + "\n");
                END;
            END;

            INT kafka_errcode = close_kafka_producer(producer, kafka_timeout);
            IF kafka_errcode!=0 THEN 
                @@kafka_error += ("Error shutting down Kafka producer: " + stringify(kafka_errcode) + "\n");
            END;
            PRINT @@kafka_error as kafkaError;
        # Else return as http response
        ELSE
            FOREACH chunk IN RANGE[0, num_chunks-1] DO
                MapAccum<UINT, STRING> @@v_batch;
                MapAccum<UINT, STRING> @@e_batch;

                res = SELECT s 
                    FROM seeds:s
                    WHERE s.@tmp_id % num_chunks == chunk
                    POST-ACCUM 
                        LIST<STRING> msg = hgt_loader_sub_{QUERYSUFFIX}(s, delimiter, num_hops, e_types, v_types),
                        BOOL is_first=True,
                        FOREACH i in msg DO
                            IF is_first THEN
                                @@v_batch += (getvid(s) -> i),
                                is_first = False
                            ELSE 
                                @@e_batch += (getvid(s) -> i)
                            END
                        END
                    LIMIT 1;

                FOREACH (k,v) IN @@v_batch DO
                    PRINT v as vertex_batch, @@e_batch.get(k) as edge_batch;
                END;
            END;
        END;
    # Else get given vertices. 
    ELSE
        MapAccum<UINT, STRING> @@v_batch;
        MapAccum<UINT, STRING> @@e_batch;
        MapAccum<UINT, VERTEX> @@id_map;

        seeds = input_vertices;
        res = SELECT s 
            FROM seeds:s 
            POST-ACCUM 
                LIST<STRING> msg = hgt_loader_sub_{QUERYSUFFIX}(s, delimiter, num_hops, e_types, v_types),
                BOOL is_first=True,
                FOREACH i in msg DO
                    IF is_first THEN
                        @@v_batch += (getvid(s) -> i),
                        is_first = False
                    ELSE 
                        @@e_batch += (getvid(s) -> i)
                    END
                END,
                @@id_map += (getvid(s) -> s)
            LIMIT 1;
        
        FOREACH (k,v) IN @@v_batch DO
            PRINT v as vertex_batch, @@e_batch.get(k) as edge_batch;
        END;

        FOREACH hop IN RANGE[1, num_hops] DO
            seeds = SELECT t
                FROM seeds:s -(e_types:e)- v_types:t
                POST-ACCUM
                    @@id_map += (getvid(t) -> t);
        END;
        PRINT @@id_map AS pids;
    END;
}