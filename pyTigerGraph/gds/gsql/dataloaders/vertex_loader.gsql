CREATE QUERY vertex_loader_{QUERYSUFFIX}(
    SET<VERTEX> input_vertices,
    STRING filter_by,
    SET<STRING> v_types,
    STRING delimiter,
    BOOL shuffle=FALSE,
    INT num_chunks=2,
    STRING kafka_address="",
    STRING kafka_topic="",
    INT kafka_topic_partitions=1,
    STRING kafka_max_size="104857600",
    INT kafka_timeout=300000,
    STRING security_protocol="",
    STRING sasl_mechanism="",
    STRING sasl_username="",
    STRING sasl_password="",
    STRING ssl_ca_location="",
    STRING ssl_certificate_location="",
    STRING ssl_key_location="",
    STRING ssl_key_password="",
    STRING ssl_endpoint_identification_algorithm="",
    STRING sasl_kerberos_service_name="",
    STRING sasl_kerberos_keytab="",
    STRING sasl_kerberos_principal=""
) SYNTAX V2 {
    /*
    This query generates batches of vertices. If `input_vertices` is given, it will generate 
    a batches of those vertices. Otherwise, it will divide all vertices into `num_batches`, 
    and return each batch separately.

    Parameters :
      input_vertices : What vertices to get.
      num_batches    : Number of batches to divide all vertices.
      shuffle        : Whether to shuffle vertices before collecting data.
      filter_by      : A Boolean attribute to determine which vertices are included.
                       Only effective when `input_vertices` is NULL.
      v_types        : Vertex types to be included.
      kafka_address  : Address of the Kafka cluster to send data to.
      kafka_topic    : The Kafka topic to send data to.
      security_protocol : Security prototol for Kafka.
      sasl_mechanism : Authentication mechanism for Kafka.
      sasl_username  : SASL username for Kafka. 
      sasl_password  : SASL password for Kafka. 
      ssl_ca_location: Path to CA certificate for verifying the Kafka broker key.
    */
    SumAccum<INT> @tmp_id;

    # If getting all vertices of given types
    IF input_vertices.size()==0 THEN
        start = {v_types};
        # Filter seeds if needed
        seeds = SELECT s
            FROM start:s
            WHERE filter_by is NULL OR s.getAttr(filter_by, "BOOL");
        # Shuffle vertex ID if needed
        IF shuffle THEN
            INT num_vertices = seeds.size();
            res = SELECT s 
                FROM seeds:s
                POST-ACCUM s.@tmp_id = floor(rand()*num_vertices)
                LIMIT 1;
        ELSE
            res = SELECT s 
                FROM seeds:s
                POST-ACCUM s.@tmp_id = getvid(s)
                LIMIT 1;
        END;
        
        # Export data
        # If using kafka to export 
        IF kafka_address != "" THEN
            SumAccum<STRING> @@kafka_error;

            # Initialize Kafka producer
            UINT producer = init_kafka_producer(
                kafka_address, kafka_max_size, security_protocol, 
                sasl_mechanism, sasl_username, sasl_password, ssl_ca_location,
                ssl_certificate_location, ssl_key_location, ssl_key_password,
                ssl_endpoint_identification_algorithm, sasl_kerberos_service_name,
                sasl_kerberos_keytab, sasl_kerberos_principal);

            FOREACH chunk IN RANGE[0, num_chunks-1] DO
                res = SELECT s 
                    FROM seeds:s
                    WHERE s.@tmp_id % num_chunks == chunk
                    POST-ACCUM
                        {VERTEXATTRSKAFKA}
                    LIMIT 1;
            END;
                
            FOREACH i IN RANGE[0, kafka_topic_partitions-1] DO
                INT kafka_errcode = write_to_kafka(producer, kafka_topic, i, "STOP", "");
                IF kafka_errcode!=0 THEN 
                    @@kafka_error += ("Error sending STOP signal to topic partition " + stringify(i) + ": " + stringify(kafka_errcode) + "\n");
                END;
            END;

            INT kafka_errcode = close_kafka_producer(producer, kafka_timeout);
            IF kafka_errcode!=0 THEN 
                @@kafka_error += ("Error shutting down Kafka producer: " + stringify(kafka_errcode) + "\n");
            END;
            PRINT @@kafka_error as kafkaError;
        # Else return as http response
        ELSE
            FOREACH chunk IN RANGE[0, num_chunks-1] DO
                ListAccum<STRING> @@v_batch;
                res = SELECT s 
                    FROM seeds:s
                    WHERE s.@tmp_id % num_chunks == chunk
                    POST-ACCUM 
                        {VERTEXATTRSHTTP}
                    LIMIT 1;

                FOREACH i IN @@v_batch DO
                    PRINT i as data_batch;
                END;
            END;
        END;
    # Else get given vertices. 
    ELSE
        ListAccum<STRING> @@v_batch;
        start = input_vertices;
        res = SELECT s 
            FROM start:s 
            POST-ACCUM 
                {VERTEXATTRSHTTP}
            LIMIT 1;
        FOREACH i IN @@v_batch DO
            PRINT i as data_batch;
        END;
    END;
}